#!/usr/bin/env python3
"""
BRAND INTELLIGENCE COLLECTOR
Phase 3 of ModaMesh‚Ñ¢: Direct Perplexity API integration for gathering comprehensive 
brand intelligence using Perplexity Sonar Pro API for deep market research.

This module creates one agent per Italian fashion brand and collects detailed
business intelligence data for market simulation.
"""

import os
import json
import logging
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, asdict
import time
import shutil

# Import for Perplexity API calls
import requests
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

# Import our Italian Fashion Market module
from italian_fashion_market import ItalianFashionMarket

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Get API key from environment variable
PERPLEXITY_API_KEY = os.getenv('PERPLEXITY_API_KEY')

@dataclass
class BrandIntelligence:
    """Complete brand intelligence data structure"""
    brand_name: str
    company_basics: Dict[str, Any]
    financial_data: Dict[str, float]
    market_position: Dict[str, Any]
    innovation_profile: Dict[str, Any]
    partnership_history: Dict[str, Any]
    brand_metrics: Dict[str, Any]
    operations: Dict[str, Any]
    competitive_position: Dict[str, Any]
    demand_elasticity: Dict[str, float]
    resilience_metrics: Dict[str, float]
    influence_metrics: Dict[str, float]
    strategic_flexibility: Dict[str, Any]
    rivalry_matrix: Dict[str, Any]
    market_dynamics: Dict[str, float]


class PerplexityClient:
    """Client for interacting with Perplexity Sonar Pro API"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.perplexity.ai/chat/completions"
        
        # Setup session with retries
        self.session = requests.Session()
        retry_strategy = Retry(
            total=4,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("https://", adapter)
        self.session.mount("http://", adapter)
    
    def query(self, prompt: str, system_prompt: str) -> Optional[str]:
        """
        Query Perplexity Sonar Pro API
        
        Args:
            prompt: User prompt
            system_prompt: System instructions
            
        Returns:
            Optional[str]: API response or None if error
        """
        headers = {
            'accept': 'application/json',
            'content-type': 'application/json',
            'Authorization': f'Bearer {self.api_key}'
        }
        
        data = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.2,  # Lower temperature for more consistent data
            "max_tokens": 4000
        }
        
        try:
            response = self.session.post(
                self.base_url,
                headers=headers,
                json=data,
                timeout=60
            )
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content']
            
        except requests.exceptions.RequestException as e:
            logger.error(f"Perplexity API error: {e}")
            return None
        except (KeyError, IndexError) as e:
            logger.error(f"Unexpected API response format: {e}")
            return None


class BrandIntelligenceAgent:
    """Agent for gathering intelligence on a specific fashion brand"""
    
    def __init__(self, brand_name: str, segments: List[str], perplexity_client: PerplexityClient):
        self.brand_name = brand_name
        self.segments = segments
        self.perplexity_client = perplexity_client
        
    def _create_system_prompt(self) -> str:
        """Create system prompt for the agent"""
        return f"""You are a JSON data extraction specialist analyzing Italian fashion brands. 

CRITICAL INSTRUCTIONS:
1. You MUST respond ONLY with valid JSON - no explanations, no markdown, no additional text
2. The JSON structure provided in the user prompt must be followed EXACTLY
3. Replace placeholder values with real data about {self.brand_name}
4. Keep all field names and structure exactly as shown
5. Never add or remove fields from the provided template

You have deep knowledge of:
- Italian fashion market and luxury brands
- Financial data and industry benchmarks  
- Market dynamics and competitive positioning
- {self.brand_name} specifically, operating in: {', '.join(self.segments)}

When exact data is unavailable, provide expert estimates based on:
- Company size and market position
- Industry benchmarks for similar brands
- Historical patterns in Italian fashion
- Publicly available information

Please answer the following question in the exact JSON format below:"""

    def _create_research_prompt(self) -> str:
        """Create the detailed research prompt for brand intelligence"""
        return f"""Research {self.brand_name} and fill in the JSON template below with accurate data.

RULES:
1. Return ONLY the JSON below - no other text
2. Replace each placeholder value with real data about {self.brand_name}
3. Keep the exact same structure and field names
4. Research {self.brand_name} to find accurate values for all fields
5. For segment_id, keep the placeholder text "[SEGMENT_PLACEHOLDER]" exactly as shown

RESPOND WITH ONLY THIS JSON:

{{
  "brand_name": "{self.brand_name}",
  
  "company_basics": {{
    "is_public": 0,
    "years_in_business": 20,
    "headquarter_italy": 1
  }},
  
  "financial_data": {{
    "annual_revenue_millions": 100.0,
    "revenue_growth_rate": 0.05,
    "profit_margin": 0.1,
    "ebitda_margin": 0.15,
    "financial_strength_score": 0.5
  }},
  
  "market_position": {{
    "segment_id": "[SEGMENT_PLACEHOLDER]",
    "avg_price_index": 500.0,
    "price_tier": 3,
    "geographic_reach": 0.5,
    "market_share_estimate": 0.02
  }},
  
  "innovation_profile": {{
    "technical_capability": 0.3,
    "r_and_d_intensity": 0.02,
    "innovation_count": 2,
    "sustainability_score": 0.4,
    "patent_count": 0
  }},
  
  "partnership_history": {{
    "total_partnerships_3yr": 3,
    "sportswear_partnerships": 0,
    "partnership_success_rate": 0.7,
    "collaboration_frequency": 0.3,
    "outsourcing_ratio": 0.5
  }},
  
  "brand_metrics": {{
    "heritage_score": 0.6,
    "innovation_perception": 0.4,
    "target_age_median": 35,
    "target_income_index": 3,
    "brand_heat": 0.5
  }},
  
  "operations": {{
    "production_flexibility": 0.5,
    "technical_manufacturing": 0.3,
    "supply_chain_complexity": 0.6,
    "digital_maturity": 0.5,
    "lead_time_index": 90
  }},
  
  "competitive_position": {{
    "competitor_count": 5,
    "competitive_intensity": 0.6,
    "differentiation_score": 0.5,
    "disruption_risk": 0.4,
    "strategic_agility": 0.5
  }},
  
  "demand_elasticity": {{
    "price_elasticity": -0.5,
    "trend_responsiveness": 0.5,
    "functionality_premium": 0.1,
    "sustainability_premium": 0.1,
    "brand_loyalty": 0.6,
    "segment_fluidity": 0.3
  }},
  
  "resilience_metrics": {{
    "covid_performance": -0.2,
    "recession_beta": 0.7,
    "crisis_recovery_speed": 0.6,
    "supply_chain_redundancy": 0.4,
    "inventory_flexibility": 0.5
  }},
  
  "influence_metrics": {{
    "market_leader_score": 0.4,
    "media_amplification": 0.5,
    "influencer_affinity": 0.5,
    "viral_potential": 0.4,
    "competitor_monitoring": 0.5
  }},
  
  "strategic_flexibility": {{
    "pivot_history": 2,
    "channel_flexibility": 0.5,
    "price_ladder_range": 0.4,
    "brand_stretch_limit": 0.3,
    "ip_dependency": 0.2
  }},
  
  "rivalry_matrix": {{
    "primary_rivals": [],
    "rivalry_intensity": {{}},
    "differentiation_axes": {{
      "price": 0.5,
      "heritage": 0.5,
      "innovation": 0.3,
      "sustainability": 0.4
    }}
  }},
  
  "market_dynamics": {{
    "home_market_advantage": 0.7,
    "new_entrant_resistance": 0.5,
    "brand_dilution_sensitivity": 0.6,
    "segment_permeability": 0.4
  }}
}}"""

    async def gather_intelligence(self) -> Optional[Dict[str, Any]]:
        """Gather comprehensive intelligence on the brand"""
        system_prompt = self._create_system_prompt()
        research_prompt = self._create_research_prompt()
        
        logger.info(f"üîç Gathering intelligence for {self.brand_name}...")
        
        # Query Perplexity
        response = self.perplexity_client.query(research_prompt, system_prompt)
        
        if not response:
            logger.error(f"‚ùå Failed to get response for {self.brand_name}")
            return None
        
        try:
            # Parse JSON response
            intelligence_data = json.loads(response)
            
            # Replace segment placeholder with actual values
            segment_ids = [int(s.split('.')[0]) for s in self.segments]
            if 'market_position' in intelligence_data and 'segment_id' in intelligence_data['market_position']:
                intelligence_data['market_position']['segment_id'] = segment_ids
            
            logger.info(f"‚úÖ Successfully gathered intelligence for {self.brand_name}")
            intelligence_data['_data_source'] = 'api_direct'  # Track that this came from API directly
            return intelligence_data
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Failed to parse JSON response for {self.brand_name}: {e}")
            
            # Try to extract valid JSON from anywhere in the response
            logger.info(f"üîß Attempting to extract valid JSON for {self.brand_name}...")
            
            # Method 1: Find JSON by looking for the main object boundaries
            try:
                # Find the first { and count braces to find the matching }
                first_brace = response.find('{')
                if first_brace >= 0:
                    brace_count = 0
                    in_string = False
                    escape_next = False
                    
                    for i in range(first_brace, len(response)):
                        char = response[i]
                        
                        # Handle string boundaries to ignore braces inside strings
                        if not escape_next:
                            if char == '"' and not in_string:
                                in_string = True
                            elif char == '"' and in_string:
                                in_string = False
                            elif char == '\\' and in_string:
                                escape_next = True
                                continue
                        else:
                            escape_next = False
                            continue
                        
                        # Count braces only outside of strings
                        if not in_string:
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    # Found the closing brace
                                    valid_json = response[first_brace:i+1]
                                    intelligence_data = json.loads(valid_json)
                                    
                                    # Replace segment placeholder with actual values
                                    segment_ids = [int(s.split('.')[0]) for s in self.segments]
                                    if 'market_position' in intelligence_data and 'segment_id' in intelligence_data['market_position']:
                                        intelligence_data['market_position']['segment_id'] = segment_ids
                                    
                                    logger.info(f"‚úÖ Successfully extracted valid JSON for {self.brand_name}")
                                    intelligence_data['_data_source'] = 'api_direct'
                                    return intelligence_data
                
            except Exception as extract_error:
                logger.error(f"Failed to extract valid JSON: {extract_error}")
            
            # Method 2: Try regex as fallback (simpler but less accurate)
            try:
                import re
                # Look for JSON object pattern
                json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
                matches = re.findall(json_pattern, response, re.DOTALL)
                
                # Try to parse each match as JSON
                for match in matches:
                    try:
                        intelligence_data = json.loads(match)
                        # Check if it looks like our expected structure
                        if 'brand_name' in intelligence_data and intelligence_data['brand_name'] == self.brand_name:
                            # Replace segment placeholder with actual values
                            segment_ids = [int(s.split('.')[0]) for s in self.segments]
                            if 'market_position' in intelligence_data and 'segment_id' in intelligence_data['market_position']:
                                intelligence_data['market_position']['segment_id'] = segment_ids
                            
                            logger.info(f"‚úÖ Successfully extracted valid JSON via regex for {self.brand_name}")
                            intelligence_data['_data_source'] = 'api_direct'
                            return intelligence_data
                    except:
                        continue
                        
            except Exception as regex_error:
                logger.error(f"Regex extraction failed: {regex_error}")
            
            logger.debug(f"Response: {response}")
            # Let's print the response to see what we're getting
            print(f"\n--- RAW RESPONSE ---\n{response}\n--- END RESPONSE ---\n")
            return None


class BrandIntelligenceOrchestrator:
    """Orchestrates the collection of brand intelligence for all Italian fashion brands"""
    
    def __init__(self, market: ItalianFashionMarket, api_key: str):
        self.market = market
        self.perplexity_client = PerplexityClient(api_key)
        self.results = {}
        self.failed_brands = []
        
    async def collect_all_brand_intelligence(self, batch_size: int = 5, delay_seconds: int = 2):
        """
        Collect intelligence for all brands in batches
        
        Args:
            batch_size: Number of brands to process in parallel
            delay_seconds: Delay between batches to respect rate limits
        """
        all_brands = self.market.get_all_brands()
        total_brands = len(all_brands)
        
        logger.info(f"üöÄ Starting intelligence collection for {total_brands} brands")
        logger.info(f"üìä Processing in batches of {batch_size} with {delay_seconds}s delay")
        
        # Process brands in batches
        for i in range(0, total_brands, batch_size):
            batch = all_brands[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (total_brands + batch_size - 1) // batch_size
            
            logger.info(f"üì¶ Processing batch {batch_num}/{total_batches}: {', '.join(batch)}")
            
            # Create agents for this batch
            agents = []
            for brand_name in batch:
                brand_info = self.market.get_brand_segments(brand_name)
                if brand_info:
                    segments = [seg.segment_name for seg in brand_info.segments]
                    agent = BrandIntelligenceAgent(brand_name, segments, self.perplexity_client)
                    agents.append(agent)
                else:
                    logger.warning(f"‚ö†Ô∏è  No segment info for {brand_name}, skipping")
                    self.failed_brands.append(brand_name)
            
            # Gather intelligence concurrently for this batch
            tasks = [agent.gather_intelligence() for agent in agents]
            results = await asyncio.gather(*tasks)
            
            # Store results
            for agent, result in zip(agents, results):
                if result:
                    self.results[agent.brand_name] = result
                else:
                    self.failed_brands.append(agent.brand_name)
            
            # Rate limit delay between batches (except for last batch)
            if i + batch_size < total_brands:
                logger.info(f"‚è≥ Waiting {delay_seconds}s before next batch...")
                await asyncio.sleep(delay_seconds)
        
        logger.info(f"‚úÖ Intelligence collection complete!")
        logger.info(f"üìä Success: {len(self.results)} brands | Failed: {len(self.failed_brands)} brands")
        
        return self.results
    
    def save_results(self, output_dir: str = "company_data"):
        """Save collected intelligence to individual JSON files per company"""
        output_path = Path(output_dir)
        
        # Delete existing directory if it exists
        if output_path.exists():
            logger.info(f"üóëÔ∏è  Removing existing {output_dir} directory...")
            shutil.rmtree(output_path)
        
        # Create fresh directory
        output_path.mkdir(exist_ok=True)
        logger.info(f"üìÅ Created fresh {output_dir} directory")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Calculate data quality statistics
        total_collected = len(self.results)
        api_direct = sum(1 for r in self.results.values() if r.get('_data_source') == 'api_direct')
        
        # Save individual company files
        if self.results:
            for brand_name, data in self.results.items():
                # Create safe filename (replace spaces and special chars)
                safe_filename = brand_name.replace(' ', '_').replace('&', 'and')
                safe_filename = ''.join(c if c.isalnum() or c in '_-' else '_' for c in safe_filename)
                
                company_file = output_path / f"{safe_filename}.json"
                
                # Remove internal tracking field before saving
                data_copy = data.copy()
                data_copy.pop('_data_source', None)
                
                with open(company_file, 'w', encoding='utf-8') as f:
                    json.dump(data_copy, f, indent=2, ensure_ascii=False)
                    
            logger.info(f"üíæ Saved {len(self.results)} individual company files to {output_dir}/")
        
        # Save failed brands list
        if self.failed_brands:
            failed_file = output_path / f"_failed_brands.json"
            with open(failed_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "failed_brands": self.failed_brands,
                    "count": len(self.failed_brands),
                    "timestamp": timestamp
                }, f, indent=2)
            logger.info(f"üìù Saved {len(self.failed_brands)} failed brands to {output_dir}/_failed_brands.json")
        
        # Save collection summary
        summary = {
            "collection_date": timestamp,
            "total_brands": len(self.market.get_all_brands()),
            "successful": len(self.results),
            "failed": len(self.failed_brands),
            "success_rate": len(self.results) / len(self.market.get_all_brands()) if self.market.get_all_brands() else 0,
            "data_quality": {
                "api_direct": api_direct,
                "api_response_rate": api_direct / total_collected if total_collected > 0 else 0,
                "default_values_used": 0,  # All our current successes come from API
                "percentage_with_real_data": 100.0 if total_collected > 0 else 0
            },
            "brands_by_segment": {}
        }
        
        # Add segment breakdown
        for segment in self.market.get_all_segments():
            segment_brands = self.market.get_segment_brands(segment)
            if segment_brands:
                collected = [b for b in segment_brands if b in self.results]
                summary["brands_by_segment"][segment] = {
                    "total": len(segment_brands),
                    "collected": len(collected),
                    "collection_rate": len(collected) / len(segment_brands),
                    "brands": collected
                }
        
        summary_file = output_path / f"_collection_summary.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2)
        logger.info(f"üìä Saved collection summary to {output_dir}/_collection_summary.json")
        
        # Print summary statistics
        print(f"\nüìä DATA QUALITY REPORT:")
        print(f"   Total brands processed: {len(self.market.get_all_brands())}")
        print(f"   Successfully collected: {total_collected}")
        print(f"   Failed to collect: {len(self.failed_brands)}")
        print(f"   \n   Data sources:")
        print(f"   - Direct API responses: {api_direct}")
        print(f"   - Default values used: 0")
        print(f"   \n   ‚úÖ Percentage with real API data: 100%")
        print(f"   ‚ùå Percentage with default values: 0%")
        print(f"\n   üìÅ All company data saved to: {output_dir}/")


async def main():
    """Main execution function"""
    print("ü§ñ MODAMESH PHASE 3: BRAND INTELLIGENCE COLLECTION")
    print("=" * 60)
    
    # Initialize market data
    market = ItalianFashionMarket()
    
    # Set up API key
    api_key = PERPLEXITY_API_KEY
    if not api_key:
        logger.error("‚ùå PERPLEXITY_API_KEY not found!")
        logger.info("üí° Please set: export PERPLEXITY_API_KEY='your-api-key'")
        return
    
    # Create orchestrator
    orchestrator = BrandIntelligenceOrchestrator(market, api_key)
    
    # Collect intelligence for all brands
    # Using smaller batches and longer delays for production
    results = await orchestrator.collect_all_brand_intelligence(
        batch_size=3,  # Process 3 brands at a time
        delay_seconds=3  # 3 second delay between batches
    )
    
    # Save results
    orchestrator.save_results()
    
    print(f"\n‚úÖ Brand Intelligence Collection Complete!")
    print(f"üìä Collected data for {len(results)} brands")
    print(f"üìÅ Results saved to 'company_data/' directory")


if __name__ == "__main__":
    # Run the async main function
    asyncio.run(main()) 